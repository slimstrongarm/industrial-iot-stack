[
  {
    "id": "opc_validation_1",
    "type": "tab",
    "label": "OPC Validation Tools",
    "disabled": false,
    "info": "Comprehensive OPC communication validation and testing tools"
  },
  {
    "id": "opc_tag_validator",
    "type": "function",
    "z": "opc_validation_1",
    "name": "OPC Tag Validator",
    "func": "// OPC Tag Validation System\nconst validation = flow.get('opcValidation') || {\n    tests: {},\n    results: {},\n    statistics: {\n        totalTests: 0,\n        passed: 0,\n        failed: 0,\n        warnings: 0,\n        lastRun: null\n    }\n};\n\nfunction validateTag(tag, expectedValue, actualValue) {\n    const test = {\n        tag: tag,\n        timestamp: Date.now(),\n        expected: expectedValue,\n        actual: actualValue,\n        status: 'pending',\n        errors: [],\n        warnings: [],\n        latency: null\n    };\n    \n    // Data type validation\n    if (typeof expectedValue !== typeof actualValue) {\n        test.errors.push(`Type mismatch: expected ${typeof expectedValue}, got ${typeof actualValue}`);\n        test.status = 'failed';\n    }\n    \n    // Value validation\n    if (typeof expectedValue === 'number') {\n        const tolerance = 0.01; // 1% tolerance for floating point\n        if (Math.abs(expectedValue - actualValue) > expectedValue * tolerance) {\n            test.errors.push(`Value mismatch: expected ${expectedValue}, got ${actualValue}`);\n            test.status = 'failed';\n        }\n    } else if (expectedValue !== actualValue) {\n        test.errors.push(`Value mismatch: expected ${expectedValue}, got ${actualValue}`);\n        test.status = 'failed';\n    }\n    \n    // Quality validation\n    if (msg.payload.quality && msg.payload.quality !== 'Good') {\n        test.warnings.push(`Quality is ${msg.payload.quality}`);\n        test.status = test.status === 'failed' ? 'failed' : 'warning';\n    }\n    \n    // Timestamp validation\n    const age = Date.now() - msg.payload.timestamp;\n    if (age > 5000) { // Data older than 5 seconds\n        test.warnings.push(`Stale data: ${age}ms old`);\n        test.status = test.status === 'failed' ? 'failed' : 'warning';\n    }\n    \n    if (test.status === 'pending') {\n        test.status = 'passed';\n    }\n    \n    return test;\n}\n\nfunction runTagTests(testConfig) {\n    const results = [];\n    \n    testConfig.forEach(config => {\n        const test = {\n            id: `test_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n            name: config.name,\n            tag: config.tag,\n            type: config.type || 'read',\n            timestamp: Date.now(),\n            results: []\n        };\n        \n        switch (config.type) {\n            case 'read':\n                // Test tag reading\n                test.results.push({\n                    operation: 'read',\n                    tag: config.tag,\n                    expected: config.expectedValue,\n                    status: 'pending'\n                });\n                break;\n                \n            case 'write':\n                // Test tag writing\n                test.results.push({\n                    operation: 'write',\n                    tag: config.tag,\n                    value: config.writeValue,\n                    status: 'pending'\n                });\n                break;\n                \n            case 'subscribe':\n                // Test tag subscription\n                test.results.push({\n                    operation: 'subscribe',\n                    tag: config.tag,\n                    interval: config.interval || 1000,\n                    status: 'pending'\n                });\n                break;\n                \n            case 'bulk':\n                // Test bulk operations\n                config.tags.forEach(tag => {\n                    test.results.push({\n                        operation: 'bulk_read',\n                        tag: tag,\n                        status: 'pending'\n                    });\n                });\n                break;\n        }\n        \n        results.push(test);\n    });\n    \n    return results;\n}\n\nif (msg.topic === 'validate_tag') {\n    const result = validateTag(\n        msg.payload.tag,\n        msg.payload.expected,\n        msg.payload.actual\n    );\n    \n    validation.results[msg.payload.tag] = result;\n    \n    // Update statistics\n    validation.statistics.totalTests++;\n    if (result.status === 'passed') validation.statistics.passed++;\n    else if (result.status === 'failed') validation.statistics.failed++;\n    else if (result.status === 'warning') validation.statistics.warnings++;\n    validation.statistics.lastRun = Date.now();\n    \n    flow.set('opcValidation', validation);\n    \n    return {\n        topic: 'validation_result',\n        payload: result\n    };\n} else if (msg.topic === 'run_tests') {\n    const tests = runTagTests(msg.payload);\n    validation.tests = tests;\n    flow.set('opcValidation', validation);\n    \n    return {\n        topic: 'tests_initiated',\n        payload: tests\n    };\n} else if (msg.topic === 'get_results') {\n    return {\n        topic: 'validation_results',\n        payload: validation\n    };\n}\n\nreturn null;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 350,
    "y": 100,
    "wires": [["opc_test_executor"]]
  },
  {
    "id": "opc_test_executor",
    "type": "function",
    "z": "opc_validation_1",
    "name": "OPC Test Executor",
    "func": "// Execute OPC tests against Ignition\nconst opcClient = global.get('opcClient') || {};\n\nasync function executeTest(test) {\n    const result = {\n        testId: test.id,\n        name: test.name,\n        startTime: Date.now(),\n        endTime: null,\n        duration: null,\n        results: [],\n        status: 'running'\n    };\n    \n    for (const operation of test.results) {\n        const opResult = {\n            ...operation,\n            startTime: Date.now(),\n            endTime: null,\n            latency: null,\n            error: null\n        };\n        \n        try {\n            switch (operation.operation) {\n                case 'read':\n                    const readStart = Date.now();\n                    const value = await readOPCTag(operation.tag);\n                    opResult.latency = Date.now() - readStart;\n                    opResult.actual = value;\n                    opResult.status = 'completed';\n                    break;\n                    \n                case 'write':\n                    const writeStart = Date.now();\n                    await writeOPCTag(operation.tag, operation.value);\n                    opResult.latency = Date.now() - writeStart;\n                    opResult.status = 'completed';\n                    // Verify write\n                    const verifyValue = await readOPCTag(operation.tag);\n                    if (verifyValue !== operation.value) {\n                        opResult.error = 'Write verification failed';\n                        opResult.status = 'failed';\n                    }\n                    break;\n                    \n                case 'subscribe':\n                    const subStart = Date.now();\n                    await subscribeOPCTag(operation.tag, operation.interval);\n                    opResult.latency = Date.now() - subStart;\n                    opResult.status = 'completed';\n                    break;\n                    \n                case 'bulk_read':\n                    const bulkStart = Date.now();\n                    const bulkValue = await readOPCTag(operation.tag);\n                    opResult.latency = Date.now() - bulkStart;\n                    opResult.actual = bulkValue;\n                    opResult.status = 'completed';\n                    break;\n            }\n        } catch (error) {\n            opResult.error = error.message;\n            opResult.status = 'failed';\n        }\n        \n        opResult.endTime = Date.now();\n        result.results.push(opResult);\n    }\n    \n    result.endTime = Date.now();\n    result.duration = result.endTime - result.startTime;\n    result.status = result.results.every(r => r.status === 'completed') ? 'passed' : 'failed';\n    \n    return result;\n}\n\n// Mock OPC functions - replace with actual OPC client calls\nasync function readOPCTag(tag) {\n    // Simulate OPC read\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve(Math.random() * 100);\n        }, Math.random() * 100 + 50);\n    });\n}\n\nasync function writeOPCTag(tag, value) {\n    // Simulate OPC write\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve();\n        }, Math.random() * 100 + 50);\n    });\n}\n\nasync function subscribeOPCTag(tag, interval) {\n    // Simulate OPC subscription\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve();\n        }, Math.random() * 50 + 25);\n    });\n}\n\nif (msg.topic === 'tests_initiated') {\n    const testPromises = msg.payload.map(test => executeTest(test));\n    \n    Promise.all(testPromises).then(results => {\n        node.send({\n            topic: 'test_results',\n            payload: results\n        });\n    }).catch(error => {\n        node.error('Test execution failed', error);\n    });\n} else {\n    return msg;\n}\n\nreturn null;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 570,
    "y": 100,
    "wires": [["opc_result_analyzer"]]
  },
  {
    "id": "opc_result_analyzer",
    "type": "function",
    "z": "opc_validation_1",
    "name": "OPC Result Analyzer",
    "func": "// Analyze OPC test results for patterns and issues\nfunction analyzeResults(results) {\n    const analysis = {\n        timestamp: Date.now(),\n        summary: {\n            totalTests: results.length,\n            passed: 0,\n            failed: 0,\n            avgLatency: 0,\n            maxLatency: 0,\n            minLatency: Infinity\n        },\n        issues: [],\n        recommendations: [],\n        performance: {\n            latencyDistribution: {},\n            slowTags: [],\n            failedTags: []\n        }\n    };\n    \n    let totalLatency = 0;\n    let latencyCount = 0;\n    \n    results.forEach(test => {\n        if (test.status === 'passed') {\n            analysis.summary.passed++;\n        } else {\n            analysis.summary.failed++;\n            analysis.issues.push({\n                test: test.name,\n                reason: 'Test failed',\n                details: test.results.filter(r => r.status === 'failed')\n            });\n        }\n        \n        test.results.forEach(result => {\n            if (result.latency) {\n                totalLatency += result.latency;\n                latencyCount++;\n                \n                if (result.latency > analysis.summary.maxLatency) {\n                    analysis.summary.maxLatency = result.latency;\n                }\n                if (result.latency < analysis.summary.minLatency) {\n                    analysis.summary.minLatency = result.latency;\n                }\n                \n                // Categorize latency\n                const bucket = Math.floor(result.latency / 50) * 50;\n                analysis.performance.latencyDistribution[bucket] = \n                    (analysis.performance.latencyDistribution[bucket] || 0) + 1;\n                \n                // Flag slow operations\n                if (result.latency > 500) {\n                    analysis.performance.slowTags.push({\n                        tag: result.tag,\n                        operation: result.operation,\n                        latency: result.latency\n                    });\n                }\n            }\n            \n            if (result.status === 'failed') {\n                analysis.performance.failedTags.push({\n                    tag: result.tag,\n                    operation: result.operation,\n                    error: result.error\n                });\n            }\n        });\n    });\n    \n    if (latencyCount > 0) {\n        analysis.summary.avgLatency = totalLatency / latencyCount;\n    }\n    \n    // Generate recommendations\n    if (analysis.summary.avgLatency > 200) {\n        analysis.recommendations.push({\n            severity: 'warning',\n            message: 'Average latency is high. Consider optimizing OPC server configuration.',\n            metric: `${analysis.summary.avgLatency.toFixed(2)}ms average`\n        });\n    }\n    \n    if (analysis.performance.slowTags.length > 5) {\n        analysis.recommendations.push({\n            severity: 'warning',\n            message: 'Multiple slow tags detected. Check network connectivity and server load.',\n            count: analysis.performance.slowTags.length\n        });\n    }\n    \n    if (analysis.summary.failed > 0) {\n        analysis.recommendations.push({\n            severity: 'error',\n            message: 'Test failures detected. Review failed tags and operations.',\n            count: analysis.summary.failed\n        });\n    }\n    \n    const successRate = (analysis.summary.passed / analysis.summary.totalTests) * 100;\n    if (successRate < 95) {\n        analysis.recommendations.push({\n            severity: 'error',\n            message: `Low success rate: ${successRate.toFixed(1)}%. Investigation required.`\n        });\n    }\n    \n    return analysis;\n}\n\nif (msg.topic === 'test_results') {\n    const analysis = analyzeResults(msg.payload);\n    \n    // Store analysis\n    const history = flow.get('opcAnalysisHistory') || [];\n    history.push(analysis);\n    if (history.length > 100) {\n        history.shift(); // Keep only last 100 analyses\n    }\n    flow.set('opcAnalysisHistory', history);\n    \n    return [\n        {\n            topic: 'analysis_complete',\n            payload: analysis\n        },\n        {\n            topic: 'dashboard_update',\n            payload: {\n                type: 'opc_validation',\n                data: analysis\n            }\n        }\n    ];\n}\n\nreturn msg;",
    "outputs": 2,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 800,
    "y": 100,
    "wires": [["opc_report_generator"], ["opc_validation_dashboard"]]
  },
  {
    "id": "opc_connectivity_tester",
    "type": "function",
    "z": "opc_validation_1",
    "name": "OPC Connectivity Tester",
    "func": "// Test OPC UA connectivity and endpoints\nconst connectivityTests = {\n    endpoint: {\n        name: 'Endpoint Discovery',\n        test: async function(config) {\n            const results = [];\n            \n            // Test endpoint discovery\n            try {\n                const endpoints = await discoverEndpoints(config.url);\n                results.push({\n                    test: 'endpoint_discovery',\n                    status: 'passed',\n                    endpoints: endpoints.length,\n                    details: endpoints\n                });\n            } catch (error) {\n                results.push({\n                    test: 'endpoint_discovery',\n                    status: 'failed',\n                    error: error.message\n                });\n            }\n            \n            return results;\n        }\n    },\n    \n    authentication: {\n        name: 'Authentication Test',\n        test: async function(config) {\n            const results = [];\n            \n            // Test different authentication methods\n            const authMethods = ['Anonymous', 'Username/Password', 'Certificate'];\n            \n            for (const method of authMethods) {\n                try {\n                    const connected = await testAuthentication(config.url, method, config.credentials);\n                    results.push({\n                        test: `auth_${method.toLowerCase()}`,\n                        status: connected ? 'passed' : 'failed',\n                        method: method\n                    });\n                } catch (error) {\n                    results.push({\n                        test: `auth_${method.toLowerCase()}`,\n                        status: 'failed',\n                        method: method,\n                        error: error.message\n                    });\n                }\n            }\n            \n            return results;\n        }\n    },\n    \n    browsing: {\n        name: 'Node Browsing Test',\n        test: async function(config) {\n            const results = [];\n            \n            // Test browsing capabilities\n            try {\n                const rootNodes = await browseNodes(config.url, 'Root');\n                results.push({\n                    test: 'browse_root',\n                    status: 'passed',\n                    nodeCount: rootNodes.length\n                });\n                \n                // Test browsing objects folder\n                const objectNodes = await browseNodes(config.url, 'Objects');\n                results.push({\n                    test: 'browse_objects',\n                    status: 'passed',\n                    nodeCount: objectNodes.length\n                });\n            } catch (error) {\n                results.push({\n                    test: 'browse_nodes',\n                    status: 'failed',\n                    error: error.message\n                });\n            }\n            \n            return results;\n        }\n    },\n    \n    subscription: {\n        name: 'Subscription Test',\n        test: async function(config) {\n            const results = [];\n            \n            // Test subscription creation\n            try {\n                const subId = await createSubscription(config.url, {\n                    requestedPublishingInterval: 1000,\n                    requestedLifetimeCount: 10000,\n                    requestedMaxKeepAliveCount: 5,\n                    maxNotificationsPerPublish: 10,\n                    publishingEnabled: true,\n                    priority: 100\n                });\n                \n                results.push({\n                    test: 'create_subscription',\n                    status: 'passed',\n                    subscriptionId: subId\n                });\n                \n                // Test monitored item creation\n                const itemId = await createMonitoredItem(subId, config.testTag);\n                results.push({\n                    test: 'create_monitored_item',\n                    status: 'passed',\n                    itemId: itemId\n                });\n            } catch (error) {\n                results.push({\n                    test: 'subscription',\n                    status: 'failed',\n                    error: error.message\n                });\n            }\n            \n            return results;\n        }\n    },\n    \n    performance: {\n        name: 'Performance Test',\n        test: async function(config) {\n            const results = [];\n            const iterations = config.iterations || 100;\n            const latencies = [];\n            \n            // Test read performance\n            for (let i = 0; i < iterations; i++) {\n                const start = Date.now();\n                try {\n                    await readValue(config.url, config.testTag);\n                    latencies.push(Date.now() - start);\n                } catch (error) {\n                    // Continue testing\n                }\n            }\n            \n            if (latencies.length > 0) {\n                const avgLatency = latencies.reduce((a, b) => a + b, 0) / latencies.length;\n                const maxLatency = Math.max(...latencies);\n                const minLatency = Math.min(...latencies);\n                \n                results.push({\n                    test: 'read_performance',\n                    status: 'passed',\n                    iterations: iterations,\n                    successRate: (latencies.length / iterations) * 100,\n                    avgLatency: avgLatency,\n                    maxLatency: maxLatency,\n                    minLatency: minLatency\n                });\n            } else {\n                results.push({\n                    test: 'read_performance',\n                    status: 'failed',\n                    error: 'No successful reads'\n                });\n            }\n            \n            return results;\n        }\n    }\n};\n\n// Mock functions - replace with actual OPC UA client calls\nasync function discoverEndpoints(url) {\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve([\n                { endpointUrl: url, securityMode: 'None' },\n                { endpointUrl: url, securityMode: 'Sign' },\n                { endpointUrl: url, securityMode: 'SignAndEncrypt' }\n            ]);\n        }, 100);\n    });\n}\n\nasync function testAuthentication(url, method, credentials) {\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve(method === 'Anonymous' || (credentials && credentials[method]));\n        }, 50);\n    });\n}\n\nasync function browseNodes(url, nodeId) {\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve(Array(Math.floor(Math.random() * 20) + 5).fill(null).map((_, i) => ({\n                nodeId: `ns=2;s=Node${i}`,\n                browseName: `Node${i}`,\n                nodeClass: 'Variable'\n            })));\n        }, 75);\n    });\n}\n\nasync function createSubscription(url, params) {\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve(`sub_${Date.now()}`);\n        }, 100);\n    });\n}\n\nasync function createMonitoredItem(subId, nodeId) {\n    return new Promise((resolve) => {\n        setTimeout(() => {\n            resolve(`item_${Date.now()}`);\n        }, 50);\n    });\n}\n\nasync function readValue(url, nodeId) {\n    return new Promise((resolve, reject) => {\n        setTimeout(() => {\n            if (Math.random() > 0.95) {\n                reject(new Error('Read failed'));\n            } else {\n                resolve(Math.random() * 100);\n            }\n        }, Math.random() * 50 + 25);\n    });\n}\n\n// Execute connectivity tests\nif (msg.topic === 'test_connectivity') {\n    const config = msg.payload;\n    const testResults = [];\n    \n    const testPromises = Object.values(connectivityTests).map(async (test) => {\n        const result = {\n            name: test.name,\n            timestamp: Date.now(),\n            results: await test.test(config)\n        };\n        return result;\n    });\n    \n    Promise.all(testPromises).then(results => {\n        node.send({\n            topic: 'connectivity_results',\n            payload: {\n                timestamp: Date.now(),\n                config: config,\n                tests: results\n            }\n        });\n    }).catch(error => {\n        node.error('Connectivity test failed', error);\n    });\n}\n\nreturn null;",
    "outputs": 1,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 370,
    "y": 200,
    "wires": [["opc_result_analyzer"]]
  },
  {
    "id": "opc_data_integrity_checker",
    "type": "function",
    "z": "opc_validation_1",
    "name": "Data Integrity Checker",
    "func": "// Check data integrity between Node-RED and Ignition\nconst integrityChecks = flow.get('integrityChecks') || {\n    active: {},\n    results: {},\n    statistics: {\n        totalChecks: 0,\n        mismatches: 0,\n        lastCheck: null\n    }\n};\n\nfunction createIntegrityCheck(config) {\n    const check = {\n        id: `check_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n        name: config.name,\n        source: config.source, // Node-RED tag/topic\n        target: config.target, // Ignition OPC tag\n        interval: config.interval || 5000,\n        tolerance: config.tolerance || 0.01,\n        timeout: config.timeout || 10000,\n        enabled: true,\n        created: Date.now(),\n        lastCheck: null,\n        status: 'pending',\n        mismatches: 0,\n        checks: 0\n    };\n    \n    return check;\n}\n\nfunction compareValues(source, target, tolerance) {\n    const comparison = {\n        timestamp: Date.now(),\n        source: {\n            value: source.value,\n            timestamp: source.timestamp,\n            quality: source.quality || 'Good'\n        },\n        target: {\n            value: target.value,\n            timestamp: target.timestamp,\n            quality: target.quality || 'Good'\n        },\n        match: false,\n        issues: []\n    };\n    \n    // Check data types\n    if (typeof source.value !== typeof target.value) {\n        comparison.issues.push({\n            type: 'type_mismatch',\n            message: `Type mismatch: source is ${typeof source.value}, target is ${typeof target.value}`\n        });\n        return comparison;\n    }\n    \n    // Check values based on type\n    if (typeof source.value === 'number') {\n        const diff = Math.abs(source.value - target.value);\n        const percentDiff = (diff / Math.abs(source.value)) * 100;\n        \n        if (percentDiff > tolerance * 100) {\n            comparison.issues.push({\n                type: 'value_mismatch',\n                message: `Value differs by ${percentDiff.toFixed(2)}%`,\n                sourcValue: source.value,\n                targetValue: target.value\n            });\n        } else {\n            comparison.match = true;\n        }\n    } else if (source.value !== target.value) {\n        comparison.issues.push({\n            type: 'value_mismatch',\n            message: 'Values do not match',\n            sourceValue: source.value,\n            targetValue: target.value\n        });\n    } else {\n        comparison.match = true;\n    }\n    \n    // Check timestamp synchronization\n    const timeDiff = Math.abs(source.timestamp - target.timestamp);\n    if (timeDiff > 5000) { // More than 5 seconds\n        comparison.issues.push({\n            type: 'timestamp_mismatch',\n            message: `Timestamps differ by ${timeDiff}ms`,\n            sourceTime: new Date(source.timestamp).toISOString(),\n            targetTime: new Date(target.timestamp).toISOString()\n        });\n    }\n    \n    // Check quality\n    if (source.quality !== 'Good' || target.quality !== 'Good') {\n        comparison.issues.push({\n            type: 'quality_issue',\n            message: 'Data quality is not Good',\n            sourceQuality: source.quality,\n            targetQuality: target.quality\n        });\n    }\n    \n    return comparison;\n}\n\nfunction performIntegrityCheck(check, sourceData, targetData) {\n    const result = compareValues(sourceData, targetData, check.tolerance);\n    \n    check.lastCheck = Date.now();\n    check.checks++;\n    \n    if (!result.match) {\n        check.mismatches++;\n        check.status = 'mismatch';\n        \n        // Store mismatch details\n        if (!integrityChecks.results[check.id]) {\n            integrityChecks.results[check.id] = [];\n        }\n        integrityChecks.results[check.id].push(result);\n        \n        // Keep only last 100 results per check\n        if (integrityChecks.results[check.id].length > 100) {\n            integrityChecks.results[check.id].shift();\n        }\n    } else {\n        check.status = 'ok';\n    }\n    \n    // Update statistics\n    integrityChecks.statistics.totalChecks++;\n    if (!result.match) {\n        integrityChecks.statistics.mismatches++;\n    }\n    integrityChecks.statistics.lastCheck = Date.now();\n    \n    // Calculate integrity score\n    const score = ((check.checks - check.mismatches) / check.checks) * 100;\n    check.integrityScore = score;\n    \n    return {\n        check: check,\n        result: result,\n        score: score\n    };\n}\n\nif (msg.topic === 'create_integrity_check') {\n    const check = createIntegrityCheck(msg.payload);\n    integrityChecks.active[check.id] = check;\n    flow.set('integrityChecks', integrityChecks);\n    \n    return {\n        topic: 'integrity_check_created',\n        payload: check\n    };\n} else if (msg.topic === 'perform_check') {\n    const checkId = msg.payload.checkId;\n    const check = integrityChecks.active[checkId];\n    \n    if (check && check.enabled) {\n        const result = performIntegrityCheck(\n            check,\n            msg.payload.sourceData,\n            msg.payload.targetData\n        );\n        \n        flow.set('integrityChecks', integrityChecks);\n        \n        return [\n            {\n                topic: 'integrity_result',\n                payload: result\n            },\n            result.result.match ? null : {\n                topic: 'integrity_alert',\n                payload: {\n                    severity: result.score < 90 ? 'critical' : 'warning',\n                    check: check.name,\n                    score: result.score,\n                    issues: result.result.issues\n                }\n            }\n        ].filter(m => m !== null);\n    }\n} else if (msg.topic === 'get_integrity_status') {\n    const status = {\n        checks: Object.values(integrityChecks.active),\n        statistics: integrityChecks.statistics,\n        overallScore: 0\n    };\n    \n    // Calculate overall integrity score\n    const activeChecks = status.checks.filter(c => c.enabled && c.checks > 0);\n    if (activeChecks.length > 0) {\n        const totalScore = activeChecks.reduce((sum, check) => sum + check.integrityScore, 0);\n        status.overallScore = totalScore / activeChecks.length;\n    }\n    \n    return {\n        topic: 'integrity_status',\n        payload: status\n    };\n}\n\nreturn null;",
    "outputs": 2,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 360,
    "y": 300,
    "wires": [["opc_report_generator"], ["opc_alert_handler"]]
  },
  {
    "id": "opc_report_generator",
    "type": "function",
    "z": "opc_validation_1",
    "name": "OPC Validation Report",
    "func": "// Generate comprehensive OPC validation reports\nfunction generateReport(data) {\n    const report = {\n        id: `report_${Date.now()}`,\n        timestamp: Date.now(),\n        type: data.topic,\n        sections: []\n    };\n    \n    switch (data.topic) {\n        case 'analysis_complete':\n            report.sections.push(generateAnalysisSection(data.payload));\n            break;\n            \n        case 'connectivity_results':\n            report.sections.push(generateConnectivitySection(data.payload));\n            break;\n            \n        case 'integrity_result':\n            report.sections.push(generateIntegritySection(data.payload));\n            break;\n            \n        case 'validation_results':\n            report.sections.push(generateValidationSection(data.payload));\n            break;\n    }\n    \n    return report;\n}\n\nfunction generateAnalysisSection(analysis) {\n    return {\n        title: 'OPC Test Analysis',\n        timestamp: new Date(analysis.timestamp).toISOString(),\n        content: [\n            {\n                type: 'summary',\n                data: {\n                    'Total Tests': analysis.summary.totalTests,\n                    'Passed': analysis.summary.passed,\n                    'Failed': analysis.summary.failed,\n                    'Success Rate': `${((analysis.summary.passed / analysis.summary.totalTests) * 100).toFixed(1)}%`,\n                    'Average Latency': `${analysis.summary.avgLatency.toFixed(2)}ms`,\n                    'Max Latency': `${analysis.summary.maxLatency}ms`,\n                    'Min Latency': `${analysis.summary.minLatency}ms`\n                }\n            },\n            {\n                type: 'issues',\n                data: analysis.issues\n            },\n            {\n                type: 'recommendations',\n                data: analysis.recommendations\n            },\n            {\n                type: 'performance',\n                data: {\n                    latencyDistribution: analysis.performance.latencyDistribution,\n                    slowTags: analysis.performance.slowTags.slice(0, 10),\n                    failedTags: analysis.performance.failedTags\n                }\n            }\n        ]\n    };\n}\n\nfunction generateConnectivitySection(results) {\n    const section = {\n        title: 'OPC Connectivity Test Results',\n        timestamp: new Date(results.timestamp).toISOString(),\n        content: []\n    };\n    \n    results.tests.forEach(test => {\n        const testResult = {\n            type: 'test',\n            name: test.name,\n            results: test.results.map(r => ({\n                test: r.test,\n                status: r.status,\n                details: r.error || r.details || `${r.status}`\n            }))\n        };\n        section.content.push(testResult);\n    });\n    \n    return section;\n}\n\nfunction generateIntegritySection(result) {\n    return {\n        title: 'Data Integrity Check',\n        timestamp: new Date().toISOString(),\n        content: [\n            {\n                type: 'check_info',\n                data: {\n                    'Check Name': result.check.name,\n                    'Source': result.check.source,\n                    'Target': result.check.target,\n                    'Total Checks': result.check.checks,\n                    'Mismatches': result.check.mismatches,\n                    'Integrity Score': `${result.score.toFixed(2)}%`\n                }\n            },\n            {\n                type: 'latest_result',\n                data: {\n                    'Match': result.result.match,\n                    'Issues': result.result.issues,\n                    'Source Value': result.result.source.value,\n                    'Target Value': result.result.target.value,\n                    'Time Difference': `${Math.abs(result.result.source.timestamp - result.result.target.timestamp)}ms`\n                }\n            }\n        ]\n    };\n}\n\nfunction generateValidationSection(validation) {\n    return {\n        title: 'Tag Validation Results',\n        timestamp: new Date().toISOString(),\n        content: [\n            {\n                type: 'statistics',\n                data: validation.statistics\n            },\n            {\n                type: 'recent_results',\n                data: Object.entries(validation.results).slice(-10).map(([tag, result]) => ({\n                    tag: tag,\n                    status: result.status,\n                    errors: result.errors,\n                    warnings: result.warnings\n                }))\n            }\n        ]\n    };\n}\n\nfunction formatReportAsText(report) {\n    let text = `\\n${'='.repeat(60)}\\n`;\n    text += `OPC VALIDATION REPORT\\n`;\n    text += `Report ID: ${report.id}\\n`;\n    text += `Generated: ${new Date(report.timestamp).toISOString()}\\n`;\n    text += `${'='.repeat(60)}\\n\\n`;\n    \n    report.sections.forEach(section => {\n        text += `${section.title}\\n`;\n        text += `${'-'.repeat(section.title.length)}\\n`;\n        \n        section.content.forEach(item => {\n            switch (item.type) {\n                case 'summary':\n                case 'check_info':\n                case 'statistics':\n                    Object.entries(item.data).forEach(([key, value]) => {\n                        text += `${key}: ${value}\\n`;\n                    });\n                    break;\n                    \n                case 'issues':\n                case 'recommendations':\n                    if (item.data.length > 0) {\n                        text += `\\n${item.type.charAt(0).toUpperCase() + item.type.slice(1)}:\\n`;\n                        item.data.forEach((d, i) => {\n                            text += `${i + 1}. ${JSON.stringify(d)}\\n`;\n                        });\n                    }\n                    break;\n                    \n                default:\n                    text += `\\n${JSON.stringify(item.data, null, 2)}\\n`;\n            }\n        });\n        text += '\\n';\n    });\n    \n    return text;\n}\n\nif (msg.topic && msg.topic.includes('_complete') || msg.topic.includes('_result')) {\n    const report = generateReport(msg);\n    const textReport = formatReportAsText(report);\n    \n    // Store report\n    const reports = flow.get('opcValidationReports') || [];\n    reports.push(report);\n    if (reports.length > 50) {\n        reports.shift();\n    }\n    flow.set('opcValidationReports', reports);\n    \n    return [\n        {\n            topic: 'report_generated',\n            payload: report\n        },\n        {\n            topic: 'report_text',\n            payload: textReport\n        }\n    ];\n}\n\nreturn null;",
    "outputs": 2,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 1020,
    "y": 150,
    "wires": [["opc_report_storage"], ["opc_report_display"]]
  },
  {
    "id": "opc_alert_handler",
    "type": "function",
    "z": "opc_validation_1",
    "name": "OPC Alert Handler",
    "func": "// Handle OPC validation alerts\nconst alerts = flow.get('opcAlerts') || {\n    active: {},\n    history: [],\n    statistics: {\n        total: 0,\n        critical: 0,\n        warning: 0,\n        resolved: 0\n    }\n};\n\nfunction createAlert(data) {\n    const alert = {\n        id: `alert_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n        timestamp: Date.now(),\n        severity: data.severity,\n        source: data.check || data.source || 'Unknown',\n        type: data.type || 'integrity',\n        message: generateAlertMessage(data),\n        details: data,\n        status: 'active',\n        acknowledged: false,\n        resolvedAt: null\n    };\n    \n    return alert;\n}\n\nfunction generateAlertMessage(data) {\n    let message = '';\n    \n    if (data.severity === 'critical') {\n        message = 'ðŸš¨ CRITICAL: ';\n    } else if (data.severity === 'warning') {\n        message = 'âš ï¸ WARNING: ';\n    }\n    \n    if (data.score !== undefined) {\n        message += `Data integrity score dropped to ${data.score.toFixed(1)}% for ${data.check}`;\n    } else if (data.issues && data.issues.length > 0) {\n        message += `${data.issues.length} issues detected in ${data.check || 'validation'}`;\n    } else {\n        message += data.message || 'Validation issue detected';\n    }\n    \n    return message;\n}\n\nfunction shouldEscalate(alert) {\n    // Escalation rules\n    const rules = [\n        {\n            condition: (a) => a.severity === 'critical' && !a.acknowledged && \n                            (Date.now() - a.timestamp) > 300000, // 5 minutes\n            action: 'page_oncall'\n        },\n        {\n            condition: (a) => a.details.score !== undefined && a.details.score < 80,\n            action: 'notify_supervisor'\n        },\n        {\n            condition: (a) => {\n                const similar = alerts.active[a.source];\n                return similar && similar.length > 5; // Multiple alerts from same source\n            },\n            action: 'create_incident'\n        }\n    ];\n    \n    for (const rule of rules) {\n        if (rule.condition(alert)) {\n            return rule.action;\n        }\n    }\n    \n    return null;\n}\n\nif (msg.topic === 'integrity_alert' || msg.topic === 'validation_alert') {\n    const alert = createAlert(msg.payload);\n    \n    // Store alert\n    if (!alerts.active[alert.source]) {\n        alerts.active[alert.source] = [];\n    }\n    alerts.active[alert.source].push(alert);\n    \n    // Update statistics\n    alerts.statistics.total++;\n    if (alert.severity === 'critical') {\n        alerts.statistics.critical++;\n    } else if (alert.severity === 'warning') {\n        alerts.statistics.warning++;\n    }\n    \n    // Check for escalation\n    const escalation = shouldEscalate(alert);\n    if (escalation) {\n        alert.escalated = escalation;\n    }\n    \n    flow.set('opcAlerts', alerts);\n    \n    const outputs = [\n        {\n            topic: 'alert_created',\n            payload: alert\n        }\n    ];\n    \n    if (escalation) {\n        outputs.push({\n            topic: 'escalate_alert',\n            payload: {\n                alert: alert,\n                action: escalation\n            }\n        });\n    }\n    \n    return outputs;\n} else if (msg.topic === 'acknowledge_alert') {\n    const alertId = msg.payload.alertId;\n    \n    // Find and acknowledge alert\n    Object.values(alerts.active).forEach(sourceAlerts => {\n        const alert = sourceAlerts.find(a => a.id === alertId);\n        if (alert) {\n            alert.acknowledged = true;\n            alert.acknowledgedBy = msg.payload.user || 'Unknown';\n            alert.acknowledgedAt = Date.now();\n        }\n    });\n    \n    flow.set('opcAlerts', alerts);\n    \n    return {\n        topic: 'alert_acknowledged',\n        payload: { alertId: alertId }\n    };\n} else if (msg.topic === 'resolve_alert') {\n    const source = msg.payload.source;\n    \n    if (alerts.active[source]) {\n        alerts.active[source].forEach(alert => {\n            if (alert.status === 'active') {\n                alert.status = 'resolved';\n                alert.resolvedAt = Date.now();\n                alerts.statistics.resolved++;\n            }\n        });\n        \n        // Move to history\n        alerts.history.push(...alerts.active[source]);\n        delete alerts.active[source];\n        \n        // Keep history limited\n        if (alerts.history.length > 1000) {\n            alerts.history = alerts.history.slice(-1000);\n        }\n    }\n    \n    flow.set('opcAlerts', alerts);\n    \n    return {\n        topic: 'alerts_resolved',\n        payload: { source: source }\n    };\n}\n\nreturn null;",
    "outputs": 2,
    "noerr": 0,
    "initialize": "",
    "finalize": "",
    "libs": [],
    "x": 590,
    "y": 350,
    "wires": [["opc_validation_dashboard"], ["opc_escalation_handler"]]
  },
  {
    "id": "opc_validation_dashboard",
    "type": "ui_template",
    "z": "opc_validation_1",
    "group": "opc_validation_group",
    "name": "OPC Validation Dashboard",
    "order": 1,
    "width": 24,
    "height": 20,
    "format": "<div id=\"opc-validation-dashboard\">\n    <style>\n        #opc-validation-dashboard {\n            font-family: Arial, sans-serif;\n            padding: 10px;\n            background: #1e1e1e;\n            color: #e0e0e0;\n        }\n        \n        .validation-header {\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n            margin-bottom: 20px;\n            padding: 15px;\n            background: #2d2d2d;\n            border-radius: 8px;\n        }\n        \n        .validation-grid {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));\n            gap: 15px;\n            margin-bottom: 20px;\n        }\n        \n        .validation-card {\n            background: #2d2d2d;\n            border-radius: 8px;\n            padding: 15px;\n            border: 1px solid #3d3d3d;\n        }\n        \n        .validation-card h3 {\n            margin: 0 0 10px 0;\n            color: #4a9eff;\n        }\n        \n        .metric {\n            display: flex;\n            justify-content: space-between;\n            padding: 5px 0;\n            border-bottom: 1px solid #3d3d3d;\n        }\n        \n        .metric:last-child {\n            border-bottom: none;\n        }\n        \n        .metric-value {\n            font-weight: bold;\n        }\n        \n        .status-good { color: #4caf50; }\n        .status-warning { color: #ff9800; }\n        .status-error { color: #f44336; }\n        \n        .test-status {\n            display: inline-block;\n            padding: 2px 8px;\n            border-radius: 4px;\n            font-size: 12px;\n            margin-left: 5px;\n        }\n        \n        .test-passed { background: #4caf50; color: white; }\n        .test-failed { background: #f44336; color: white; }\n        .test-warning { background: #ff9800; color: white; }\n        \n        .latency-chart {\n            height: 200px;\n            margin-top: 10px;\n        }\n        \n        .alert-list {\n            max-height: 300px;\n            overflow-y: auto;\n        }\n        \n        .alert-item {\n            padding: 10px;\n            margin-bottom: 5px;\n            border-radius: 4px;\n            display: flex;\n            justify-content: space-between;\n            align-items: center;\n        }\n        \n        .alert-critical { background: #f44336; color: white; }\n        .alert-warning { background: #ff9800; color: white; }\n        \n        .control-button {\n            padding: 8px 16px;\n            border: none;\n            border-radius: 4px;\n            cursor: pointer;\n            margin-right: 10px;\n            background: #4a9eff;\n            color: white;\n            transition: background 0.3s;\n        }\n        \n        .control-button:hover {\n            background: #357abd;\n        }\n        \n        .progress-bar {\n            width: 100%;\n            height: 20px;\n            background: #3d3d3d;\n            border-radius: 10px;\n            overflow: hidden;\n            margin-top: 5px;\n        }\n        \n        .progress-fill {\n            height: 100%;\n            background: #4caf50;\n            transition: width 0.5s ease;\n        }\n        \n        .test-runner {\n            background: #252525;\n            border-radius: 8px;\n            padding: 20px;\n            margin-top: 20px;\n        }\n        \n        .test-config {\n            display: grid;\n            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n            gap: 15px;\n            margin-bottom: 20px;\n        }\n        \n        .config-input {\n            display: flex;\n            flex-direction: column;\n        }\n        \n        .config-input label {\n            margin-bottom: 5px;\n            color: #a0a0a0;\n        }\n        \n        .config-input input, .config-input select {\n            padding: 8px;\n            border-radius: 4px;\n            border: 1px solid #3d3d3d;\n            background: #1e1e1e;\n            color: #e0e0e0;\n        }\n    </style>\n    \n    <div class=\"validation-header\">\n        <h2>OPC Validation Dashboard</h2>\n        <div>\n            <span id=\"last-update\">Last Update: Never</span>\n            <button class=\"control-button\" onclick=\"runAllTests()\">Run All Tests</button>\n            <button class=\"control-button\" onclick=\"clearResults()\">Clear Results</button>\n        </div>\n    </div>\n    \n    <div class=\"validation-grid\">\n        <!-- Summary Card -->\n        <div class=\"validation-card\">\n            <h3>Validation Summary</h3>\n            <div class=\"metric\">\n                <span>Total Tests</span>\n                <span class=\"metric-value\" id=\"total-tests\">0</span>\n            </div>\n            <div class=\"metric\">\n                <span>Passed</span>\n                <span class=\"metric-value status-good\" id=\"tests-passed\">0</span>\n            </div>\n            <div class=\"metric\">\n                <span>Failed</span>\n                <span class=\"metric-value status-error\" id=\"tests-failed\">0</span>\n            </div>\n            <div class=\"metric\">\n                <span>Success Rate</span>\n                <span class=\"metric-value\" id=\"success-rate\">0%</span>\n            </div>\n            <div class=\"progress-bar\">\n                <div class=\"progress-fill\" id=\"success-progress\" style=\"width: 0%\"></div>\n            </div>\n        </div>\n        \n        <!-- Performance Card -->\n        <div class=\"validation-card\">\n            <h3>Performance Metrics</h3>\n            <div class=\"metric\">\n                <span>Average Latency</span>\n                <span class=\"metric-value\" id=\"avg-latency\">0ms</span>\n            </div>\n            <div class=\"metric\">\n                <span>Max Latency</span>\n                <span class=\"metric-value\" id=\"max-latency\">0ms</span>\n            </div>\n            <div class=\"metric\">\n                <span>Min Latency</span>\n                <span class=\"metric-value\" id=\"min-latency\">0ms</span>\n            </div>\n            <div class=\"metric\">\n                <span>Slow Operations</span>\n                <span class=\"metric-value status-warning\" id=\"slow-ops\">0</span>\n            </div>\n            <div class=\"latency-chart\" id=\"latency-chart\"></div>\n        </div>\n        \n        <!-- Connectivity Status -->\n        <div class=\"validation-card\">\n            <h3>Connectivity Status</h3>\n            <div class=\"metric\">\n                <span>Endpoint Discovery</span>\n                <span class=\"test-status\" id=\"endpoint-status\">Pending</span>\n            </div>\n            <div class=\"metric\">\n                <span>Authentication</span>\n                <span class=\"test-status\" id=\"auth-status\">Pending</span>\n            </div>\n            <div class=\"metric\">\n                <span>Node Browsing</span>\n                <span class=\"test-status\" id=\"browse-status\">Pending</span>\n            </div>\n            <div class=\"metric\">\n                <span>Subscriptions</span>\n                <span class=\"test-status\" id=\"sub-status\">Pending</span>\n            </div>\n        </div>\n        \n        <!-- Data Integrity -->\n        <div class=\"validation-card\">\n            <h3>Data Integrity</h3>\n            <div class=\"metric\">\n                <span>Active Checks</span>\n                <span class=\"metric-value\" id=\"active-checks\">0</span>\n            </div>\n            <div class=\"metric\">\n                <span>Total Comparisons</span>\n                <span class=\"metric-value\" id=\"total-comparisons\">0</span>\n            </div>\n            <div class=\"metric\">\n                <span>Mismatches</span>\n                <span class=\"metric-value status-error\" id=\"mismatches\">0</span>\n            </div>\n            <div class=\"metric\">\n                <span>Overall Score</span>\n                <span class=\"metric-value\" id=\"integrity-score\">100%</span>\n            </div>\n            <div class=\"progress-bar\">\n                <div class=\"progress-fill\" id=\"integrity-progress\" style=\"width: 100%\"></div>\n            </div>\n        </div>\n    </div>\n    \n    <!-- Active Alerts -->\n    <div class=\"validation-card\">\n        <h3>Active Alerts</h3>\n        <div class=\"alert-list\" id=\"alert-list\">\n            <p style=\"text-align: center; color: #666;\">No active alerts</p>\n        </div>\n    </div>\n    \n    <!-- Test Runner -->\n    <div class=\"test-runner\">\n        <h3>Test Configuration</h3>\n        <div class=\"test-config\">\n            <div class=\"config-input\">\n                <label>OPC Server URL</label>\n                <input type=\"text\" id=\"opc-url\" value=\"opc.tcp://localhost:4840\" />\n            </div>\n            <div class=\"config-input\">\n                <label>Test Tag</label>\n                <input type=\"text\" id=\"test-tag\" value=\"ns=2;s=TestTag\" />\n            </div>\n            <div class=\"config-input\">\n                <label>Test Type</label>\n                <select id=\"test-type\">\n                    <option value=\"connectivity\">Connectivity</option>\n                    <option value=\"validation\">Tag Validation</option>\n                    <option value=\"integrity\">Data Integrity</option>\n                    <option value=\"performance\">Performance</option>\n                    <option value=\"all\">All Tests</option>\n                </select>\n            </div>\n            <div class=\"config-input\">\n                <label>Iterations</label>\n                <input type=\"number\" id=\"iterations\" value=\"100\" min=\"1\" max=\"1000\" />\n            </div>\n        </div>\n        <button class=\"control-button\" onclick=\"runConfiguredTest()\">Run Test</button>\n    </div>\n</div>\n\n<script>\n(function(scope) {\n    // Update dashboard with new data\n    scope.$watch('msg', function(msg) {\n        if (!msg || !msg.payload) return;\n        \n        const data = msg.payload;\n        \n        if (data.type === 'opc_validation') {\n            updateValidationSummary(data.data);\n        } else if (msg.topic === 'connectivity_results') {\n            updateConnectivityStatus(data);\n        } else if (msg.topic === 'integrity_status') {\n            updateIntegrityStatus(data);\n        } else if (msg.topic === 'alert_created') {\n            addAlert(data);\n        }\n        \n        updateLastUpdate();\n    });\n    \n    function updateValidationSummary(data) {\n        document.getElementById('total-tests').textContent = data.summary.totalTests;\n        document.getElementById('tests-passed').textContent = data.summary.passed;\n        document.getElementById('tests-failed').textContent = data.summary.failed;\n        \n        const successRate = (data.summary.passed / data.summary.totalTests) * 100;\n        document.getElementById('success-rate').textContent = successRate.toFixed(1) + '%';\n        document.getElementById('success-progress').style.width = successRate + '%';\n        \n        document.getElementById('avg-latency').textContent = data.summary.avgLatency.toFixed(2) + 'ms';\n        document.getElementById('max-latency').textContent = data.summary.maxLatency + 'ms';\n        document.getElementById('min-latency').textContent = data.summary.minLatency + 'ms';\n        document.getElementById('slow-ops').textContent = data.performance.slowTags.length;\n        \n        // Update latency chart\n        updateLatencyChart(data.performance.latencyDistribution);\n    }\n    \n    function updateConnectivityStatus(data) {\n        const statusMap = {\n            'endpoint_discovery': 'endpoint-status',\n            'authentication': 'auth-status',\n            'browsing': 'browse-status',\n            'subscription': 'sub-status'\n        };\n        \n        data.tests.forEach(test => {\n            const allPassed = test.results.every(r => r.status === 'passed');\n            const statusElement = document.getElementById(statusMap[test.name.toLowerCase().replace(' ', '_')]);\n            if (statusElement) {\n                statusElement.textContent = allPassed ? 'Passed' : 'Failed';\n                statusElement.className = 'test-status ' + (allPassed ? 'test-passed' : 'test-failed');\n            }\n        });\n    }\n    \n    function updateIntegrityStatus(data) {\n        document.getElementById('active-checks').textContent = data.checks.filter(c => c.enabled).length;\n        document.getElementById('total-comparisons').textContent = data.statistics.totalChecks;\n        document.getElementById('mismatches').textContent = data.statistics.mismatches;\n        document.getElementById('integrity-score').textContent = data.overallScore.toFixed(1) + '%';\n        document.getElementById('integrity-progress').style.width = data.overallScore + '%';\n        \n        const progressBar = document.getElementById('integrity-progress');\n        if (data.overallScore < 90) {\n            progressBar.style.background = '#f44336';\n        } else if (data.overallScore < 95) {\n            progressBar.style.background = '#ff9800';\n        } else {\n            progressBar.style.background = '#4caf50';\n        }\n    }\n    \n    function addAlert(alert) {\n        const alertList = document.getElementById('alert-list');\n        \n        // Clear placeholder if exists\n        if (alertList.children.length === 1 && alertList.children[0].tagName === 'P') {\n            alertList.innerHTML = '';\n        }\n        \n        const alertDiv = document.createElement('div');\n        alertDiv.className = 'alert-item alert-' + alert.severity;\n        alertDiv.innerHTML = `\n            <div>\n                <strong>${alert.source}</strong>\n                <div>${alert.message}</div>\n                <small>${new Date(alert.timestamp).toLocaleTimeString()}</small>\n            </div>\n            <button class=\"control-button\" onclick=\"acknowledgeAlert('${alert.id}')\">Ack</button>\n        `;\n        \n        alertList.insertBefore(alertDiv, alertList.firstChild);\n        \n        // Keep only last 10 alerts\n        while (alertList.children.length > 10) {\n            alertList.removeChild(alertList.lastChild);\n        }\n    }\n    \n    function updateLatencyChart(distribution) {\n        // Simple text-based chart for latency distribution\n        const chart = document.getElementById('latency-chart');\n        let html = '<div style=\"font-size: 12px;\">';\n        \n        const maxCount = Math.max(...Object.values(distribution));\n        \n        Object.entries(distribution).sort((a, b) => parseInt(a[0]) - parseInt(b[0])).forEach(([bucket, count]) => {\n            const barWidth = (count / maxCount) * 100;\n            html += `\n                <div style=\"margin: 2px 0;\">\n                    <span style=\"display: inline-block; width: 60px;\">${bucket}ms:</span>\n                    <div style=\"display: inline-block; width: calc(100% - 100px); background: #3d3d3d; height: 15px; border-radius: 3px;\">\n                        <div style=\"width: ${barWidth}%; background: #4a9eff; height: 100%; border-radius: 3px;\"></div>\n                    </div>\n                    <span style=\"margin-left: 5px;\">${count}</span>\n                </div>\n            `;\n        });\n        \n        html += '</div>';\n        chart.innerHTML = html;\n    }\n    \n    function updateLastUpdate() {\n        document.getElementById('last-update').textContent = 'Last Update: ' + new Date().toLocaleTimeString();\n    }\n    \n    // Global functions for button clicks\n    window.runAllTests = function() {\n        scope.send({\n            topic: 'run_tests',\n            payload: [\n                { name: 'Basic Read Test', tag: 'ns=2;s=TestTag', type: 'read', expectedValue: 100 },\n                { name: 'Write Test', tag: 'ns=2;s=TestTag', type: 'write', writeValue: 200 },\n                { name: 'Subscription Test', tag: 'ns=2;s=TestTag', type: 'subscribe', interval: 1000 },\n                { name: 'Bulk Test', tags: ['ns=2;s=Tag1', 'ns=2;s=Tag2', 'ns=2;s=Tag3'], type: 'bulk' }\n            ]\n        });\n    };\n    \n    window.clearResults = function() {\n        // Clear displays\n        document.getElementById('alert-list').innerHTML = '<p style=\"text-align: center; color: #666;\">No active alerts</p>';\n        // Reset counters\n        ['total-tests', 'tests-passed', 'tests-failed', 'slow-ops', 'active-checks', 'total-comparisons', 'mismatches'].forEach(id => {\n            document.getElementById(id).textContent = '0';\n        });\n        document.getElementById('success-rate').textContent = '0%';\n        document.getElementById('integrity-score').textContent = '100%';\n    };\n    \n    window.runConfiguredTest = function() {\n        const config = {\n            url: document.getElementById('opc-url').value,\n            testTag: document.getElementById('test-tag').value,\n            type: document.getElementById('test-type').value,\n            iterations: parseInt(document.getElementById('iterations').value)\n        };\n        \n        if (config.type === 'connectivity' || config.type === 'all') {\n            scope.send({\n                topic: 'test_connectivity',\n                payload: config\n            });\n        }\n        \n        if (config.type === 'validation' || config.type === 'all') {\n            scope.send({\n                topic: 'run_tests',\n                payload: [\n                    { name: 'Configured Test', tag: config.testTag, type: 'read', expectedValue: 100 }\n                ]\n            });\n        }\n        \n        if (config.type === 'integrity' || config.type === 'all') {\n            scope.send({\n                topic: 'create_integrity_check',\n                payload: {\n                    name: 'Manual Check',\n                    source: 'node-red/' + config.testTag,\n                    target: config.testTag,\n                    interval: 5000\n                }\n            });\n        }\n    };\n    \n    window.acknowledgeAlert = function(alertId) {\n        scope.send({\n            topic: 'acknowledge_alert',\n            payload: { alertId: alertId, user: 'Operator' }\n        });\n    };\n})(scope);\n</script>",
    "storeOutMessages": true,
    "fwdInMessages": true,
    "resendOnRefresh": true,
    "templateScope": "local",
    "x": 840,
    "y": 450,
    "wires": [[]]
  },
  {
    "id": "opc_test_scheduler",
    "type": "inject",
    "z": "opc_validation_1",
    "name": "Schedule Tests",
    "props": [
      {
        "p": "payload"
      },
      {
        "p": "topic",
        "vt": "str"
      }
    ],
    "repeat": "300",
    "crontab": "",
    "once": false,
    "onceDelay": 0.1,
    "topic": "run_tests",
    "payload": "[{\"name\":\"Scheduled Read Test\",\"tag\":\"ns=2;s=Temperature\",\"type\":\"read\",\"expectedValue\":75},{\"name\":\"Scheduled Write Test\",\"tag\":\"ns=2;s=Setpoint\",\"type\":\"write\",\"writeValue\":80}]",
    "payloadType": "json",
    "x": 140,
    "y": 100,
    "wires": [["opc_tag_validator"]]
  },
  {
    "id": "opc_report_storage",
    "type": "file",
    "z": "opc_validation_1",
    "name": "Store Reports",
    "filename": "/tmp/opc_validation_reports.log",
    "appendNewline": true,
    "createDir": true,
    "overwriteFile": "false",
    "encoding": "utf8",
    "x": 1240,
    "y": 130,
    "wires": [[]]
  },
  {
    "id": "opc_report_display",
    "type": "debug",
    "z": "opc_validation_1",
    "name": "Display Report",
    "active": true,
    "tosidebar": true,
    "console": false,
    "tostatus": false,
    "complete": "payload",
    "targetType": "msg",
    "statusVal": "",
    "statusType": "auto",
    "x": 1240,
    "y": 170,
    "wires": []
  },
  {
    "id": "opc_escalation_handler",
    "type": "link out",
    "z": "opc_validation_1",
    "name": "To Alert System",
    "links": [],
    "x": 795,
    "y": 370,
    "wires": []
  },
  {
    "id": "opc_validation_group",
    "type": "ui_group",
    "name": "OPC Validation",
    "tab": "opc_validation_tab",
    "order": 1,
    "disp": true,
    "width": "24",
    "collapse": false
  },
  {
    "id": "opc_validation_tab",
    "type": "ui_tab",
    "name": "OPC Validation",
    "icon": "dashboard",
    "order": 1,
    "disabled": false,
    "hidden": false
  }
]